# AV-ASR 基础模型开发需求文档
## 一、项目概述
### 1. 项目目标
开发一款**极简架构的视听融合语音识别（AV-ASR）基础模型**，不依赖大模型（参数量控制在100M以内），通过独立的视频特征编码器与音频特征编码器提取双模态特征，最终经CTC解码实现时序对齐与语音转录，验证视觉特征对音频识别的基础互补作用。

### 2. 核心定位
- 技术定位：基础验证型模型，聚焦“双模态编码+CTC解码”的核心流程，不引入复杂模块（如自注意力、多任务训练、预训练微调）；
- 应用场景：适用于干净/低噪声环境的短语音转录（5秒内 utterance），支持英文基础词汇识别（核心验证功能，非生产级应用）；
- 核心价值：快速验证“视听融合”的技术可行性，为后续复杂模型优化提供基础参照。

## 二、功能需求
### 1. 输入输出
- 输入：
  - 音频：16kHz采样率、单通道、WAV格式音频片段（时长1-5秒）；
  - 视频：30fps帧率、128×128分辨率、仅含单人唇部区域的视频片段（与音频时序严格同步）；
- 输出：
  - 转录文本：英文小写字母+空格+基础标点（. , ! ?）；
  - 辅助输出：CTC解码的帧级token概率分布（可选，用于调试）。

### 2. 核心功能
- 双模态特征提取：独立编码音频与视频特征，不涉及跨模态早期融合；
- CTC时序对齐：通过CTC损失解决“音频/视频帧序列→文本token序列”的非对齐问题；
- 基础识别能力：在干净环境下，对500词以内英文词汇的转录WER（词错误率）≤15%；
- 轻量化推理：单条5秒音频+视频推理延迟≤100ms（CPU环境）。

### 3. 非功能需求
- 模型规模：总参数量≤100M，避免复杂网络结构（如Transformer、LSTM深层堆叠）；
- 训练效率：单GPU（16GB显存）训练时长≤24小时，支持批量训练（batch size≥16）；
- 兼容性：支持PyTorch 1.10+框架，可导出ONNX格式用于部署；
- 可调试性：输出训练过程中的WER、损失值曲线，支持单样本特征可视化。

## 三、技术需求
### 1. 数据要求
- 数据集：采用公开小型AV-ASR数据集（如LRW-subset、GRID），包含：
  - 训练集：≥1万条样本（音频+视频+转录文本），覆盖10-20名说话人；
  - 验证集/测试集：各≥1千条样本，与训练集说话人无重叠；
- 数据预处理：
  - 音频：提取40维log-mel谱图特征（25ms窗口、10ms步长），全局归一化；
  - 视频：裁剪唇部区域（128×128），转为灰度图，按帧提取64维HOG特征（或简单CNN特征）；
  - 文本：统一为小写，过滤特殊字符，构建≤500词的词汇表（含空白符<blank>）。

### 2. 模型架构（极简设计）
#### （1）音频编码器
- 结构：3层2D卷积网络（Conv2d）+ 2层全连接层；
- 参数：卷积核大小3×3，通道数依次为32→64→128， stride=2；全连接层输出维度256；
- 激活函数：ReLU，无BatchNorm（简化训练）。

#### （2）视频编码器
- 结构：与音频编码器对称，3层2D卷积网络（Conv2d）+ 2层全连接层；
- 参数：卷积核大小3×3，通道数依次为32→64→128， stride=2；全连接层输出维度256；
- 激活函数：ReLU，无BatchNorm。

#### （3）特征融合与CTC头
- 融合方式：特征级拼接（音频特征256维 + 视频特征256维 = 512维融合特征）；
- CTC头：1层全连接层，将512维融合特征映射到词汇表维度（含<blank>，维度=501）；
- 损失函数：标准CTC损失（blank_id=0，reduction="mean"）。

### 3. 训练配置
- 优化器：Adam，初始学习率1e-4，学习率衰减策略：验证集WER3轮无下降则衰减为原来的0.5；
- 训练轮数：最多50轮，早停策略（验证集WER5轮无下降则停止）；
- 正则化：仅使用Dropout（概率0.1，仅全连接层添加）；
- 批量处理：动态padding（音频/视频帧序列按批次最长长度padding，填充值=0）。

### 4. 解码配置
- 解码方式：基础贪心解码（逐帧取概率最大token）；
- 后处理：按CTC规则折叠路径（合并相邻重复token+删除空白符<blank>）；
- 可选优化：支持束搜索（beam size=5，仅用于测试，不增加训练复杂度）。

## 四、交付物
1. 源代码：
   - 数据预处理脚本（音频/视频特征提取、文本编码）；
   - 模型定义代码（音频编码器、视频编码器、CTC头）；
   - 训练/验证/测试脚本（含损失计算、WER评估、早停逻辑）；
   - 推理脚本（支持单样本/批量推理，输出转录文本）。
2. 模型文件：
   - 训练完成的最优模型权重（.pth格式）；
   - ONNX格式导出文件（用于部署验证）。
3. 文档：
   - 数据预处理说明（含特征提取细节、词汇表）；
   - 模型架构详细参数表（各层输入输出维度、参数量）；
   - 训练日志（损失值、WER变化曲线）；
   - 测试报告（测试集WER、推理延迟、典型样本转录结果）。

## 五、约束条件
1. 技术限制：
   - 禁止使用预训练模型（如CLIP、wav2vec系列）；
   - 禁止使用复杂网络模块（如Transformer、LSTM、注意力机制）；
   - 禁止引入额外模态或多任务训练（仅聚焦“音频+视频→文本”转录）。
2. 环境限制：
   - 训练环境：单GPU（≥16GB显存），CPU≥8核，内存≥32GB；
   - 推理环境：支持CPU/GPU，无特殊硬件依赖。